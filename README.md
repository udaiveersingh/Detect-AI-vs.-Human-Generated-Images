# Detect-AI-vs.-Human-Generated-Images

## Problem Statement
The rise of generative AI has brought remarkable advancements in creating realistic images, videos, and audio. However, with this progress comes the challenge of distinguishing between authentic human-created content and AI-generated content, particularly in the context of deepfakes. Deepfake detection has become a critical area of research due to its implications for media trust, security, and ethics. Misuse of generative AI can lead to the spread of misinformation, erosion of public trust, and potential harm to individuals and institutions. <br>

## Dataset
The dataset for this challenge, provided by Shutterstock and DeepMedia, combines authentic and AI-generated images to create a robust foundation for training and evaluation. Authentic images are sourced from Shutterstock's platform, including a balanced selection where one-third of the images feature humans. These are paired with their AI-generated counterparts, created by DeepMedia using state-of-the-art generative models.<br>
The data can be accessed here: https://www.kaggle.com/datasets/alessandrasala79/ai-vs-human-generated-dataset
<br> 

## Evaluation
Primary Metric: Primary evaluation metric is the F1-Score, which balances precision and recall to measure the modelâ€™s effectiveness in identifying AI-generated and human-created images. It is calculated at the 0.5 threshold. <br>

## What this project Brings
- Real-World Impact: Tackle the challenge of deepfake detection, a critical issue for media authenticity and security.
- Skill Development: Gain hands-on experience with dataset from industry leaders.
- Global Recognition: Compete with data scientists worldwide and showcase your work.
- Inclusivity: Be part of a challenge that promotes diversity and fairness in AI.
